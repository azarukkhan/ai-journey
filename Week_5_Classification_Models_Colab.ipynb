{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad42f3b",
   "metadata": {},
   "source": [
    "\n",
    "# Week 5 â€“ Classification Models (Colab Format)\n",
    "\n",
    "This week you'll build a **classification model** with scikit-learn. You'll learn how to:\n",
    "- Load a labeled dataset\n",
    "- Train/test split\n",
    "- Train a simple classifier\n",
    "- Evaluate with **accuracy, precision, recall, F1**, confusion matrix, and **ROC AUC**\n",
    "- Explain results in plain English for stakeholders\n",
    "\n",
    "**No heavy math** â€” just practical steps.\n",
    "\n",
    "**How to use in Google Colab**\n",
    "1. Download this notebook.\n",
    "2. Open https://colab.research.google.com\n",
    "3. File â†’ Upload notebook â†’ select this file.\n",
    "4. Run cells top to bottom (Shift + Enter).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Free Learning Resources\n",
    "- Kaggle: [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)\n",
    "- scikit-learn: [Classification](https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eb898",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "\n",
    "np.__version__, pd.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d4a4e",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load Dataset\n",
    "\n",
    "We'll use scikit-learn's built-in **Breast Cancer** dataset (binary classification). The goal is to predict whether a tumor is malignant or benign.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5719023",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Features & Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b078efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]  # 0 = malignant, 1 = benign\n",
    "X.shape, y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b8a71",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98aeb5",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Baseline Model: Logistic Regression\n",
    "\n",
    "We'll standardize features (common with linear models), then fit the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee98e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_proba_lr = log_reg.predict_proba(X_test_scaled)[:, 1]  # needed for ROC AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd010b7f",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Evaluate: Accuracy, Precision, Recall, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bdf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_classification(y_true, y_pred, y_proba=None, positive_label=1):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, pos_label=positive_label)\n",
    "    rec = recall_score(y_true, y_pred, pos_label=positive_label)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=positive_label)\n",
    "    print(f\"Accuracy:  {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall:    {rec:.3f}\")\n",
    "    print(f\"F1 score:  {f1:.3f}\")\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_true, y_proba)\n",
    "        print(f\"ROC AUC:   {auc:.3f}\")\n",
    "\n",
    "eval_classification(y_test, y_pred_lr, y_proba_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c2c33",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Confusion Matrix (Visual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
    "disp.plot(values_format='d')\n",
    "plt.title(\"Logistic Regression â€“ Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa9fbc",
   "metadata": {},
   "source": [
    "\n",
    "## 7) ROC Curve (Visual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca03a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba_lr)\n",
    "plt.title(\"Logistic Regression â€“ ROC Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b36dd",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Try a Different Model: Random Forest\n",
    "\n",
    "Tree-based models often perform well without scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest metrics:\")\n",
    "eval_classification(y_test, y_pred_rf, y_proba_rf)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=data.target_names).plot(values_format='d')\n",
    "plt.title(\"Random Forest â€“ Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba_rf)\n",
    "plt.title(\"Random Forest â€“ ROC Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93201b",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Plain-English Interpretation (Client-Friendly)\n",
    "\n",
    "Use the printed metrics and plots to explain:\n",
    "- What does **precision** vs **recall** mean here?\n",
    "- Which model would you choose and why?\n",
    "- What trade-offs matter for stakeholders (e.g., missing a malignant case vs false alarms)?\n",
    "\n",
    "*(Double-click this cell in Colab to write your notes.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605f61f",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Optional: Threshold Tuning\n",
    "\n",
    "Try changing the decision threshold from 0.5 to another value and see how precision/recall trade off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: custom threshold for logistic regression\n",
    "threshold = 0.4  # try 0.3, 0.6, etc.\n",
    "y_pred_thresh = (y_proba_lr >= threshold).astype(int)\n",
    "print(f\"Using threshold={threshold}\")\n",
    "eval_classification(y_test, y_pred_thresh, y_proba_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd72b4c",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Week 5 Deliverables\n",
    "- Train **two classifiers** (Logistic Regression + Random Forest)\n",
    "- Report Accuracy, Precision, Recall, F1, ROC AUC\n",
    "- Include a Confusion Matrix and ROC Curve\n",
    "- Short business explanation of the trade-offs\n",
    "- (Bonus) Show how a different threshold changes metrics\n",
    "\n",
    "**Next (Week 6):** Framing AI projects for business (use-case mapping & ROI thinking).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925cc53f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¤ Save Your Work to GitHub\n",
    "1) File â†’ Download â†’ Download `.ipynb`  \n",
    "2) In GitHub Desktop, **Show in Explorer** â†’ copy the file into your `ai-journey` repo  \n",
    "3) Commit: `Add Week 5 Colab notebook` â†’ **Push origin**  \n",
    "4) Add a new section in `README.md` with an **Open in Colab** badge pointing to:  \n",
    "   `https://colab.research.google.com/github/YOUR_USERNAME/ai-journey/blob/main/Week_5_Classification_Models_Colab.ipynb`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
